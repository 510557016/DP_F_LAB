1. tesseract install 
pip install Pillow
pip install pytesseract
sudo add-apt-repository ppa:alex-p/tesseract-ocr-devel
sudo apt install -y tesseract-ocr
sudo apt update

2. python readability
pip3 install https://github.com/andreasvc/readability/tarball/master

import readability
text = ('This is an example sentence .\n'
        'Note that tokens are separated by spaces and sentences by newlines .\n')
results = readability.getmeasures(text, lang='en')
print(results['readability grades']['FleschReadingEase'])

OrderedDict([('readability grades', OrderedDict([('Kincaid', 7.442500000000003), ('ARI', 5.825624999999999), ('Coleman-Liau', 9.532550312500003), ('FleschReadingEase', 55.95250000000002), ('GunningFogIndex', 10.700000000000001), ('LIX', 39.25), ('SMOGIndex', 9.70820393249937), ('RIX', 2.5), ('DaleChallIndex', 9.954550000000001)])), ('sentence info', OrderedDict([('characters_per_word', 4.9375), ('syll_per_word', 1.6875), ('words_per_sentence', 8.0), ('sentences_per_paragraph', 2.0), ('type_token_ratio', 0.9375), ('characters', 79), ('syllables', 27), ('words', 16), ('wordtypes', 15), ('sentences', 2), ('paragraphs', 1), ('long_words', 5), ('complex_words', 3), ('complex_words_dc', 6)])), ('word usage', OrderedDict([('tobeverb', 2), ('auxverb', 0), ('conjunction', 1), ('pronoun', 2), ('preposition', 2), ('nominalization', 1)])), ('sentence beginnings', OrderedDict([('pronoun', 1), ('interrogative', 0), ('article', 0), ('subordination', 0), ('conjunction', 0), ('preposition', 0)]))])

nlp 處理步驟 分詞 ＝> 前置處理 => 去除停用詞 ＝> 字詞出現次數統計

3.NLTK
(程式)
pip install nltk 
(詞庫)
python3.8
>>import nltk
>>nltk.download() 
l)List 
>>nltk.download('all')  

4. 清除 html tag
pip3 install beautifulsoup4
pip3 install html5lib     

5. google news search
pip3 install GoogleNews        

6.  download dataSet
Kaggle : News_Category_Dataset_v3.json

7. JSON2CSV.py 
json format trans to csv and format suitable for spark model

8. upload train_data.csv google cloud HD

9. train model on colab
        1. Install Java 8 and NLU
        
                !wget https://setup.johnsnowlabs.com/nlu/colab.sh -O - | bash
                

        2.make train_set, test_set
        
                import nlu
                import pandas as pd
                test_path = '/content/drive/MyDrive/train_data.csv'
                train_df = pd.read_csv(test_path,usecols = ['category','description'])
                train_df.dropna(inplace=True)
                train_df.columns=['y','text']

                from sklearn.model_selection import train_test_split

                train_df, test_df = train_test_split(train_df, test_size=0.2)
                train_df

        3.Train Deep Learning Classifier using nlu.load('train.classifier',gpu=True)
        
                fitted_pipe = nlu.load('train.classifier').fit(train_df)
                preds = fitted_pipe.predict(train_df,output_level = 'document')
                preds

        4.Evaluate the model

                from sklearn.metrics import classification_report
                print(classification_report(preds['y'], preds['classifier_dl']))

        5.different Sentence Emebddings  

                fitted_pipe = nlu.load('en.embed_sentence.small_bert_L12_768 train.classifier',gpu=True).fit(train_df)
                preds = fitted_pipe.predict(train_df,output_level='document')
                print(classification_report(preds['y'], preds['classifier_dl']))

        6.evaluate on Test Data

                preds = fitted_pipe.predict(test_df,output_level='document')
                preds.dropna(inplace=True)
                print(classification_report(preds['y'], preds['classifier_dl']))

        7.save the model

                stored_model_path = './models/classifier_dl_trained' 
                fitted_pipe.save(stored_model_path)  

        8.load the model

                hdd_pipe = nlu.load(path=stored_model_path)
                preds = hdd_pipe.predict('Tesla plans to invest 10M into the ML sector')
                preds
                hdd_pipe.print_info()

10. 本機安裝 nlp 套件
        
        pip3 install pyspark==3.3.0 
        pip3 install spark-nlp==4.2.4                
                




